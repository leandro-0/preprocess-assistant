{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ff561d12fd9c05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T18:45:54.470214Z",
     "start_time": "2025-02-25T18:45:54.401570Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.high_level import LTPage\n",
    "from nltk.corpus import wordnet as wn\n",
    "from pdfminer.layout import LTTextContainer, LTTextLineVertical, LTTextBoxHorizontal, LTTextBox, Rect\n",
    "import wordninja\n",
    "from pdf2image import convert_from_path\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1fa45591f25e59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:01:40.325777Z",
     "start_time": "2025-02-25T22:01:40.321678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\000.pdf',\n",
       " 'data\\\\001.pdf',\n",
       " 'data\\\\002.pdf',\n",
       " 'data\\\\003.pdf',\n",
       " 'data\\\\004.pdf',\n",
       " 'data\\\\101404-Texto del artículo-379745-1-10-20230814.pdf',\n",
       " 'data\\\\103822-Texto del artículo-398336-1-10-20240109.pdf',\n",
       " 'data\\\\103827-Texto del artículo-398338-1-10-20240109.pdf',\n",
       " 'data\\\\108896-Texto del artículo-430136-1-10-20240723.pdf',\n",
       " 'data\\\\110685-Texto del artículo-444650-1-10-20241017.pdf',\n",
       " 'data\\\\113135-Texto del artículo-461992-1-10-20250121.pdf',\n",
       " 'data\\\\113136-Texto del artículo-461995-1-10-20250121.pdf',\n",
       " 'data\\\\130-Texto del artículo en fichero de Microsoft Word o LibreOffice (necesario)-134-1-10-20090331.pdf',\n",
       " 'data\\\\32502-Texto del artículo-103690-1-10-20150102 (1).pdf',\n",
       " 'data\\\\32502-Texto del artículo-103690-1-10-20150102.pdf',\n",
       " 'data\\\\32511-Texto del artículo-103699-1-10-20150102.pdf',\n",
       " 'data\\\\32519-Texto del artículo-103707-1-10-20150102.pdf',\n",
       " 'data\\\\32576-Texto del artículo-103765-1-10-20150102.pdf',\n",
       " 'data\\\\32585-Texto del artículo-103775-1-10-20150102.pdf',\n",
       " 'data\\\\32738-Texto del artículo-103935-1-10-20150102.pdf',\n",
       " 'data\\\\32766-Texto del artículo-103969-1-10-20150102.pdf',\n",
       " 'data\\\\32793-Texto del artículo-104000-1-10-20150102.pdf',\n",
       " 'data\\\\32808-Texto del artículo-104015-1-10-20150102.pdf',\n",
       " 'data\\\\67980-Texto del artículo-210492-1-10-20181017.pdf',\n",
       " 'data\\\\68036-Texto del artículo-210659-1-10-20181018.pdf',\n",
       " 'data\\\\68116-Texto del artículo-210919-1-10-20181022.pdf',\n",
       " 'data\\\\68195-Texto del artículo-211113-1-10-20181024.pdf',\n",
       " 'data\\\\68514-Texto del artículo-212200-1-10-20181107.pdf',\n",
       " 'data\\\\68520-Texto del artículo-212210-1-10-20181107.pdf',\n",
       " 'data\\\\74375-Texto del artículo-237795-1-10-20190926.pdf',\n",
       " 'data\\\\86232-Texto del artículo-285270-1-10-20201123.pdf',\n",
       " 'data\\\\90048-Texto del artículo-305353-1-10-20210621.pdf',\n",
       " 'data\\\\97886-Texto del artículo-355772-1-10-20230113.pdf',\n",
       " 'data\\\\99593-Texto del artículo-367964-1-10-20230426.pdf',\n",
       " 'data\\\\Codesarrollo-la-opción-institucional-para-el-vínculo-migración-y-desarrollo.pdf',\n",
       " 'data\\\\Construyendo-Teotitlán-tapetes-migrantes-gringos-y-etnógrafos.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "articles = [os.path.join(\"data\", art) for art in os.listdir(\"data\")]\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d18af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_footnote_line(article_path: str, page: LTPage, page_number: int, DPI: int = 100) -> list[dict[str, float]]:\n",
    "    page_w, page_h = page.bbox[2], page.bbox[3]\n",
    "    raw_image = convert_from_path(article_path, dpi=DPI, first_page=page_number+1, last_page=page_number+1)[0]\n",
    "    img = np.array(raw_image)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img_height, img_width = gray.shape\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 1))\n",
    "    morph = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "    edges = cv2.Canny(morph, 50, 200, apertureSize=3)\n",
    "\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=30, maxLineGap=20)\n",
    "    if lines is None:\n",
    "        return None\n",
    "\n",
    "    pdfminer_lines = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        # Escalar a coordenadas PDFMiner\n",
    "        y1_pdf = (y1 / img_height) * page_h\n",
    "        y2_pdf = (y2 / img_height) * page_h\n",
    "\n",
    "        pdfminer_lines.append({\n",
    "            \"x1\": x1,\n",
    "            \"y1\": page_h - y1_pdf,\n",
    "            \"x2\": x2,\n",
    "            \"y2\": page_h - y2_pdf\n",
    "        })\n",
    "\n",
    "    threshold_y = page_h * 0.35\n",
    "    filtered_lines = [line for line in pdfminer_lines if line[\"y1\"] <= threshold_y]\n",
    "    filtered_lines.sort(key=lambda line: line[\"y1\"], reverse=True)\n",
    "    return filtered_lines[0] if filtered_lines else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "328c6f30a1fe9c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:01:43.600110Z",
     "start_time": "2025-02-25T22:01:43.596107Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_page(pdf_path, page):\n",
    "    pages = extract_pages(pdf_path)\n",
    "    for i, page_layout in enumerate(pages):\n",
    "        if i != page - 1: continue\n",
    "        return page_layout\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex stop conditions\n",
    "references_re = r\"(?i)^\\s*(referencias|bibliografía citada|bibliografia citada|bibliografía|bibliografia|citas|fuentes|referencias bibliograficas|referencias bibliográficas)\\s*$\"\n",
    "\n",
    "# regex delete\n",
    "version_logs = r\"(?i)(recibido|aceptado|publicado|(segunda|tercera|cuarta|quinta|sexta) versión)[,:]?\\s*(el\\s*)?(\\d{1,2}(\\s*de)?\\s*[a-záéíóú]+(\\s*de\\s*\\d{4})?|\\d{1,2}/\\d{1,2}/\\d{4})(\\s*\\.\\s*)?\"\n",
    "\n",
    "footnote_references = r\"([.,;:!?])([0-9]+)\"\n",
    "duplicated_spaces = r\"\\s+\"\n",
    "\n",
    "# recognizing regex\n",
    "abstract = r\"Palabras clave|Keywords|Resumen|Abstract|Key words|Palabrasclave|Keyword|Palabra clave|Palabras claves|Keywords|Sumario|Síntesis|Sintesis|Sinopsis\"\n",
    "\n",
    "# parentesis y llaves\n",
    "parentheses_pattern = r'\\(' + \\\n",
    "                      r'(?:' + \\\n",
    "                      r'(?:[^;)]+)' + \\\n",
    "                      r'(?:; [^;)]+)*' + \\\n",
    "                      r')\\)'\n",
    "brackets_pattern = r'\\[' + \\\n",
    "                      r'(?:' + \\\n",
    "                      r'(?:[^;\\]]+)' + \\\n",
    "                      r'(?:; [^;\\]]+)*' + \\\n",
    "                      r')\\]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa9dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleExtractedData:\n",
    "    def __init__(self, pdf_path: str):\n",
    "        self.pdf_path: str = pdf_path\n",
    "        self.headers: set[str] = set()\n",
    "        self.footers: set[str] = set()\n",
    "        self.footnotes_lines: list[dict[str, float]] = []\n",
    "        self.start_page: int = 0\n",
    "\n",
    "def extract_data_article(pdf_path) -> ArticleExtractedData:\n",
    "    data = ArticleExtractedData(pdf_path)\n",
    "    headers_counter: map[str, int] = {}\n",
    "    footers_counter: map[str, int] = {}\n",
    "    found_page = None\n",
    "\n",
    "    for i, page in enumerate(extract_pages(pdf_path)):\n",
    "        height = page.bbox[3]\n",
    "        cutoff = height * 0.35\n",
    "\n",
    "        footnote_line = identify_footnote_line(pdf_path, page, i)\n",
    "        data.footnotes_lines.append(footnote_line)\n",
    "\n",
    "        for element in page:\n",
    "            if not isinstance(element, (LTTextBox, LTTextBox, LTTextContainer)):\n",
    "                continue\n",
    "            txt = element.get_text().strip()\n",
    "            if element.bbox[3] <= cutoff:\n",
    "                footers_counter[txt] = footers_counter.get(txt, 0) + 1\n",
    "            if element.bbox[1] >= height - cutoff:\n",
    "                headers_counter[txt] = headers_counter.get(txt, 0) + 1\n",
    "            \n",
    "            # Stop searching for abstract after 3 pages\n",
    "            if found_page is not None or i > 2:\n",
    "                continue\n",
    "\n",
    "            text_semiclean = re.sub(duplicated_spaces, \" \", txt).strip()\n",
    "            if re.search(abstract, text_semiclean, re.IGNORECASE):\n",
    "                found_page = i\n",
    "\n",
    "\n",
    "    data.headers = {k for k, v in headers_counter.items() if v > 1 and len(k) > 0}\n",
    "    data.footers = {k for k, v in footers_counter.items() if v > 1 and len(k) > 0}\n",
    "    if found_page is not None:\n",
    "        data.start_page = found_page\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a837c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stop_conditions(text) -> bool:\n",
    "\treturn any([\n",
    "\t\tre.search(references_re, text, flags=re.MULTILINE),\n",
    "\t])\n",
    "\n",
    "def clean_unwanted_patterns(text) -> str:\n",
    "\t# Eliminar patrones como \"Recibido el 12 de marzo de 2021.\"\n",
    "    text = re.sub(version_logs, \"\", text).strip()\n",
    "\n",
    "    # ()\n",
    "    text = re.sub(parentheses_pattern, \"\", text).strip()\n",
    "    \n",
    "    # []\n",
    "    text = re.sub(brackets_pattern, \"\", text).strip()\n",
    "    \n",
    "    # .1 ?2 !4 :5 ;6\n",
    "    text = re.sub(footnote_references, r\"\\1\", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "def clean_page(text) -> str:\n",
    "    text = text.replace(\"-\\n\", \"\")\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"«\", \"\").replace(\"»\", \"\").replace(\"“\", \"\").replace(\"”\", \"\").replace(\"‘\", \"\").replace(\"’\", \"\")\n",
    "    text = text.replace('\"', \"\").replace(\"'\", \"\")\n",
    "    text = re.sub(duplicated_spaces, \" \", text).strip()\n",
    "    return text.lower()\n",
    "\n",
    "# (str, bool) -> (text, continue?)\n",
    "def extract_page_text(page: LTPage, page_number: int, data: ArticleExtractedData) -> tuple[str, bool]:\n",
    "    text = \"\"\n",
    "    status = True\n",
    "    if page_number <= data.start_page:\n",
    "        return text, status\n",
    "\n",
    "    for element in page:\n",
    "        if not isinstance(element, (LTTextBoxHorizontal, LTTextBox, LTTextContainer)):\n",
    "            continue\n",
    "\n",
    "        _, __, ___, y2 = element.bbox\n",
    "        footnote_line = data.footnotes_lines[page_number]\n",
    "        if y2 <= (footnote_line[\"y1\"] if footnote_line is not None else -1):\n",
    "            break\n",
    "\n",
    "        txt = element.get_text().strip()\n",
    "        if txt.isdigit() or txt in data.headers or txt in data.footers:\n",
    "            continue\n",
    "\n",
    "        if check_stop_conditions(txt):\n",
    "            status = False\n",
    "            break\n",
    "\n",
    "        text += txt + \"\\n\"\n",
    "\n",
    "    text = clean_unwanted_patterns(text)\n",
    "    text = clean_page(text)\n",
    "    return text, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81362f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('el imaginario colectivo admite aún hoy que la guerra contra el indígena que despobló el sur argentino, entre 1875 y 1885, se libró contra un enemigo salvaje e inadaptable a la sociedad dominante, a quien era necesario eliminar para poder incorporar grandes espacios al mercado nacional. esa concepción se alimenta en fuentes que en su momento —la etapa formativa de la antropología— fueron la ciencia generalmente aceptada. el conocimiento científico de los indígenas de la patagonia y tierra del fuego se inició con el registro caótico de datos por parte de viajeros europeos, y hacia fines del siglo xviii, con la crítica de esa información y las primeras hipótesis evolucionistas generadas en la comparación etnográfica de las culturas. la ciencia metropolitana española —encarnada en las expediciones de córdoba y de malaspina— estudió a los patagones y fueguinos en función de los intereses coloniales y elaboró una primera clasificación distintiva de salvajes y bárbaros; y esa imagen evolucionista de las civilizaciones funcionó como legitimadora de decisiones políticas: en el momento en que se construyó esa visión, la decisión central fue abandonar la patagonia; un siglo después, sería conquistarla. 1. leyenda, realidad y desencantamiento de los gigantes patagones en la época de la ilustración tradicionalmente se ha defendido que la descripción de la patagonia del jesuita thomas falkner 1, publicada en inglaterra, inició los estudios científicos del hombre patagónico. sin embargo, no hay allí un trabajo que refleje el estado de las ciencias del hombre a fines del siglo de la ilustración, hasta el paso por la patagonia de las expediciones de antonio de córdoba y de alejandro malaspina, que podemos considerar partes de una misma iniciativa. en la introducción a la relación del primer viaje de córdoba , los responsables declaran la intención de seguir el modelo inglés de registro de datos sobre la navegación, y de participar de un nuevo modo en la competencia internacional. con la decadencia general de españa —se alega— todas las naciones comenzaron a publicar sus viajes, al punto de que cook llega a dudar de la autenticidad de los viajes españoles del siglo xvi, aún inéditos. el resultado del develamiento propuesto y del uso del mejor instrumental científico inglés y de la biblioteca de malaspina, cedida gentilmente, sería la reivindicación de las glorias españolas. desde su planteamiento inicial a fines de 1788, el viaje de malaspina alrededor del mundo buscaba también algo que queda claro por las palabras que usa el comandante: emulación, progreso, investigación, descubrimiento . emulación de inglaterra y francia siguiendo las trazas de los señores cook y la pérouse, que han emprendido una noble emulación entre ellos. emulación para la cual españa no estaba preparada: sí en cuanto a la posibilidad de reunir un grupo de científicos capa-',\n",
       " True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art = articles[2]\n",
    "data = extract_data_article(art)\n",
    "page = extract_page(art, 2)\n",
    "extract_page_text(page, 1, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "183559bb16e20cbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:02:41.521599Z",
     "start_time": "2025-02-25T22:02:41.345192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LTTextBoxHorizontal(0) 131.553,617.258,367.336,625.258 'REFORMA, ORDEN Y CONCIERTO EN EL PERÚ DEL SIGLO XVII\\n'>\n",
      "<LTTextBoxHorizontal(1) 85.038,387.647,413.873,601.046 'constantemente  con  los  otros  miembros  de  la  élite  de  poder  en  materias\\nreferentes  a  aumento  de  impuestos,  envío  de  remesas  y  colaboración\\ncomercial.  Mantener  el  equilibrio  no  fue  tarea  fácil  y,  de  hecho,  hubo\\ncoyunturas muy tensas entre los diversos actores sociales, sobre todo cuan-\\ndo  se  intentó  forzar  a  los  reinos  americanos  a  realizar  mayores  aportes\\npecuniarios a la península. Los «beneméritos» nunca cejaron en sus inten-\\ntos de obtener los puestos que los propios virreyes repartían entre sus cria-\\ndos. La Iglesia, por su parte, se mantuvo firme en defender los privilegios\\nconcedidos desde el siglo XVI, que la favorecían con la percepción de diez-\\nmos, inmunidad, cesión de tierras y beneficios fiscales. La administración\\nfue ineficiente y progresivamente ciertas funciones del Estado fueron dele-\\ngándose en manos privadas, particularmente en el Consulado.4 Finalmente,\\nlos comerciantes de Lima formaron grandes consorcios en el interior del\\nvirreinato que les permitieron lanzar una ofensiva contundente en el comer-\\ncio  atlántico  a  través  de  sus  factores  —los  «peruleros»—,  que  dejó  en\\nmalas condiciones tanto al comercio peninsular como al mismo sistema de\\ngaleones.5\\n'>\n",
      "<LTTextBoxHorizontal(2) 85.034,197.898,413.865,385.998 'En este contexto, y como expresión de la práctica política de la épo-\\nca, aparecieron diversos escritos sobre el Perú que trataron de diagnosticar\\ny remediar alguno de estos males aunque, como afirma Amadori, la histo-\\nriografía  americanista  no  les  ha  prestado  mucha  atención.6.  El  fenómeno\\nque  más  ha  sido  estudiado  es  la  aparición  de  arbitrios  en  las  décadas  de\\n1620 y 1630, incentivada por el conde-duque de Olivares, la mayoría de los\\ncuales  tenía  como  finalidad  hacer  más  eficiente  la  extorsión  fiscal  de  las\\nIndias.7 Un  buen  ejemplo  es  el  «Parecer»  del  contador  Hernando  de\\nValencia, cuyo arbitrio explicaba los daños que había ocasionado la planta-\\nción de viñas en el Perú y recomendaba volver a prohibir el comercio de\\nvinos  peruanos  para  aumentar  el  consumo  de  aquellos  procedentes  de\\nEspaña.8 El arbitrio de Diego Pérez Gallego estaba orientado, por el contra-\\nrio, a exaltar las virtudes del gobierno del virrey conde de Chinchón, pero\\ntambién incluía un diagnóstico de los principales problemas del Perú y los\\nremedios necesarios para subsanar los errores.9\\n'>\n",
      "<LTTextBoxHorizontal(3) 112.220,138.453,413.854,183.253 '4 Suárez, 2012.\\n5 Suárez, 2009.\\n6 Amadori, 2009, 152.\\n7 Idem; Amadori, 2013, 139; Bronner, 1974, 1975, 1981, 1981a.\\n8 Archivo General de Indias (AGI), Lima, 162, Parecer del contador Hernando de Valencia,\\n'>\n",
      "<LTTextBoxHorizontal(4) 85.036,129.253,116.788,137.253 'año 1633.\\n'>\n",
      "<LTTextBoxHorizontal(5) 112.220,120.053,220.109,128.053 '9 Pérez Gallego, 1945, 295-326.\\n'>\n",
      "<LTTextBoxHorizontal(6) 85.039,93.542,327.778,99.542 'Anu. estud. am., 71, 1, enero-junio, 2014, 25-46. ISSN: 0210-5810. DOI: 10.3989/aeamer.2014.1.02\\n'>\n",
      "<LTTextBoxHorizontal(7) 402.858,93.541,413.858,104.541 '27\\n'>\n",
      "<LTRect 85.039,93.543,413.858,626.457>\n",
      "<LTRect 85.039,93.543,413.858,192.756>\n",
      "<LTLine 85.039,189.895,136.063,189.895>\n",
      "<LTRect 85.039,600.945,413.858,626.457>\n",
      "<LTRect 85.039,93.543,413.858,119.055>\n",
      "<LTRect 385.512,93.543,413.858,119.055>\n"
     ]
    }
   ],
   "source": [
    "page = extract_page(articles[1], 3)\n",
    "for element in page:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [os.path.join(\"data\", art) for art in os.listdir(\"data\")]\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "349b8631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(pdf_path: str) -> str:\n",
    "    text = \"\"\n",
    "    data = extract_data_article(pdf_path)\n",
    "    for i, page in enumerate(extract_pages(pdf_path)):\n",
    "        page_text, can_continue = extract_page_text(page, i, data)\n",
    "        text = f\"{text} {page_text}\"\n",
    "        if not can_continue:\n",
    "            break\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_text = {}\n",
    "for article in articles:\n",
    "    articles_text[article] = extract_pdf_text(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "41e560c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(articles_text.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4546167",
   "metadata": {},
   "source": [
    "# Buscador tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b3f5e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d1d5f",
   "metadata": {},
   "source": [
    "Cargado de contriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e2ffff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/contriever\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d8a233",
   "metadata": {},
   "source": [
    "Generar embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8b128ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, model, tokenizer):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "embeddings = get_embeddings(texts, model, tokenizer)\n",
    "embeddings_np = embeddings.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d5625",
   "metadata": {},
   "source": [
    "Creacion del indice FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "350ca368",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = embeddings_np.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4e564f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos más relevantes: [[25 32 23  6  9]]\n",
      "Distancias: [[3.7350006 3.8825526 3.8842738 3.895139  4.0316696]]\n"
     ]
    }
   ],
   "source": [
    "def search(query, model, tokenizer, index, top_k=5):\n",
    "    query_embedding = get_embeddings([query], model, tokenizer).numpy()\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    return indices, distances\n",
    "\n",
    "query = \"Llegada de Belveder a Perú\"\n",
    "indices, distances = search(query, model, tokenizer, index)\n",
    "print(\"Documentos más relevantes:\", indices)\n",
    "print(\"Distancias:\", distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
