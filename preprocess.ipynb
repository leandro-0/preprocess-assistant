{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ff561d12fd9c05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T18:45:54.470214Z",
     "start_time": "2025-02-25T18:45:54.401570Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.high_level import LTPage\n",
    "from nltk.corpus import wordnet as wn\n",
    "from pdfminer.layout import LTTextContainer, LTTextLineVertical, LTTextBoxHorizontal, LTTextBox, Rect\n",
    "import wordninja\n",
    "from pdf2image import convert_from_path\n",
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpanishLanguageModel(wordninja.LanguageModel):\n",
    "    def __init__(self, word_file):\n",
    "        super().__init__(word_file)\n",
    "        self.SPLIT_RE = re.compile(\"[^a-zA-Z0-9áéíóúÁÉÍÓÚñÑ']+\")\n",
    "    \n",
    "    def split(self, s):\n",
    "        l = [self._split(x) for x in self.SPLIT_RE.split(s)]\n",
    "        return [item for sublist in l for item in sublist]\n",
    "wordninja.DEFAULT_LANGUAGE_MODEL = SpanishLanguageModel(\"words.txt.gz\")\n",
    "\n",
    "def separate_words(text):\n",
    "    sep = wordninja.split(text)\n",
    "    return \" \".join(sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7be3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a1fa45591f25e59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:01:40.325777Z",
     "start_time": "2025-02-25T22:01:40.321678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\000.pdf',\n",
       " 'data\\\\001.pdf',\n",
       " 'data\\\\002.pdf',\n",
       " 'data\\\\003.pdf',\n",
       " 'data\\\\004.pdf',\n",
       " 'data\\\\101404-Texto del artículo-379745-1-10-20230814.pdf',\n",
       " 'data\\\\103822-Texto del artículo-398336-1-10-20240109.pdf',\n",
       " 'data\\\\103827-Texto del artículo-398338-1-10-20240109.pdf',\n",
       " 'data\\\\108896-Texto del artículo-430136-1-10-20240723.pdf',\n",
       " 'data\\\\110685-Texto del artículo-444650-1-10-20241017.pdf',\n",
       " 'data\\\\113135-Texto del artículo-461992-1-10-20250121.pdf',\n",
       " 'data\\\\113136-Texto del artículo-461995-1-10-20250121.pdf',\n",
       " 'data\\\\130-Texto del artículo en fichero de Microsoft Word o LibreOffice (necesario)-134-1-10-20090331.pdf',\n",
       " 'data\\\\32502-Texto del artículo-103690-1-10-20150102 (1).pdf',\n",
       " 'data\\\\32502-Texto del artículo-103690-1-10-20150102.pdf',\n",
       " 'data\\\\32511-Texto del artículo-103699-1-10-20150102.pdf',\n",
       " 'data\\\\32519-Texto del artículo-103707-1-10-20150102.pdf',\n",
       " 'data\\\\32576-Texto del artículo-103765-1-10-20150102.pdf',\n",
       " 'data\\\\32585-Texto del artículo-103775-1-10-20150102.pdf',\n",
       " 'data\\\\32738-Texto del artículo-103935-1-10-20150102.pdf',\n",
       " 'data\\\\32766-Texto del artículo-103969-1-10-20150102.pdf',\n",
       " 'data\\\\32793-Texto del artículo-104000-1-10-20150102.pdf',\n",
       " 'data\\\\32808-Texto del artículo-104015-1-10-20150102.pdf',\n",
       " 'data\\\\67980-Texto del artículo-210492-1-10-20181017.pdf',\n",
       " 'data\\\\68036-Texto del artículo-210659-1-10-20181018.pdf',\n",
       " 'data\\\\68116-Texto del artículo-210919-1-10-20181022.pdf',\n",
       " 'data\\\\68195-Texto del artículo-211113-1-10-20181024.pdf',\n",
       " 'data\\\\68514-Texto del artículo-212200-1-10-20181107.pdf',\n",
       " 'data\\\\68520-Texto del artículo-212210-1-10-20181107.pdf',\n",
       " 'data\\\\74375-Texto del artículo-237795-1-10-20190926.pdf',\n",
       " 'data\\\\86232-Texto del artículo-285270-1-10-20201123.pdf',\n",
       " 'data\\\\90048-Texto del artículo-305353-1-10-20210621.pdf',\n",
       " 'data\\\\97886-Texto del artículo-355772-1-10-20230113.pdf',\n",
       " 'data\\\\99593-Texto del artículo-367964-1-10-20230426.pdf',\n",
       " 'data\\\\Codesarrollo-la-opción-institucional-para-el-vínculo-migración-y-desarrollo.pdf',\n",
       " 'data\\\\Construyendo-Teotitlán-tapetes-migrantes-gringos-y-etnógrafos.pdf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "articles = [os.path.join(\"data\", art) for art in os.listdir(\"data\")]\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d18af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_possible_footnote_line(article_path: str, page: LTPage, page_number: int, DPI: int = 100) -> list[dict[str, float]]:\n",
    "    page_w, page_h = page.bbox[2], page.bbox[3]\n",
    "    raw_image = convert_from_path(article_path, dpi=DPI, first_page=page_number+1, last_page=page_number+1)[0]\n",
    "    img = np.array(raw_image)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img_height, img_width = gray.shape\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 1))\n",
    "    morph = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "    edges = cv2.Canny(morph, 50, 200, apertureSize=3)\n",
    "\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=30, maxLineGap=20)\n",
    "    if lines is None:\n",
    "        return None\n",
    "\n",
    "    pdfminer_lines = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        # Escalar a coordenadas PDFMiner\n",
    "        y1_pdf = (y1 / img_height) * page_h\n",
    "        y2_pdf = (y2 / img_height) * page_h\n",
    "\n",
    "        pdfminer_lines.append({\n",
    "            \"x1\": x1,\n",
    "            \"y1\": page_h - y1_pdf,\n",
    "            \"x2\": x2,\n",
    "            \"y2\": page_h - y2_pdf\n",
    "        })\n",
    "\n",
    "    threshold_y = page_h * 0.35\n",
    "    filtered_lines = [line for line in pdfminer_lines if line[\"y1\"] <= threshold_y]\n",
    "    filtered_lines.sort(key=lambda line: line[\"y1\"], reverse=True)\n",
    "    return filtered_lines[0] if filtered_lines else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3461fa5ac6ff93",
   "metadata": {},
   "source": [
    "**arreglar**:\n",
    "\n",
    "etno-\\ngráfico -> etnográfico -> .replace(\"-\\n\", \"\")\n",
    "\n",
    "**tomar en cuenta toda la pagina hasta donde aparece el primer patron de pie de pagina**\n",
    "\n",
    "**quitar**:\n",
    "- citas como (Banks, 2001)\n",
    "\n",
    "**arreglar**:\n",
    "- hay conjunto de palabras que aparecen juntos, por ejemplo, lacercania en lugar de \n",
    "la cercania (art4, pag3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "328c6f30a1fe9c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:01:43.600110Z",
     "start_time": "2025-02-25T22:01:43.596107Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_page(pdf_path, page):\n",
    "    pages = extract_pages(pdf_path)\n",
    "    for i, page_layout in enumerate(pages):\n",
    "        if i != page - 1: continue\n",
    "        return page_layout\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex stop conditions\n",
    "references_re = r\"(?i)^\\s*(referencias|bibliografía citada|bibliografia citada|bibliografía|bibliografia|citas|fuentes|referencias bibliograficas|referencias bibliográficas)\\s*$\"\n",
    "\n",
    "# regex delete\n",
    "version_logs = r\"(?i)(recibido|aceptado|publicado|(segunda|tercera|cuarta|quinta|sexta) versión)[,:]?\\s*(el\\s*)?(\\d{1,2}(\\s*de)?\\s*[a-záéíóú]+(\\s*de\\s*\\d{4})?|\\d{1,2}/\\d{1,2}/\\d{4})(\\s*\\.\\s*)?\"\n",
    "footnote_patterns = r\"(?m)^(?:\\d+|[*†‡¹²³⁴⁵⁶⁷⁸⁹]+|\\[\\d+\\])\\s+.*$\"\n",
    "\n",
    "footnote_references = r\"\\.[0-9]+|[0-9]+\\.\"\n",
    "duplicated_spaces = r\"\\s+\"\n",
    "\n",
    "# recognizing regex\n",
    "abstract = r\"Palabras clave|Keywords|Resumen|Abstract|Key words|Palabrasclave|Keyword|Palabra clave|Palabras claves|Keywords|Sumario|Síntesis|Sintesis|Sinopsis\"\n",
    "\n",
    "# cites\n",
    "cites_general_pattern = r'\\(' + \\\n",
    "                r'(?:' + \\\n",
    "                    r'(?:\"[\\wáéíóúÁÉÍÓÚñÑ\\s]+\"?, \\d{4})|' + \\\n",
    "                    r'(?:[\\wáéíóúÁÉÍÓÚñÑ\\s]+ et al\\., (?:s\\.f\\.|(?:\\d{4}[a-z]?))(?:, p\\. \\d+)?)|' + \\\n",
    "                    r'(?:[\\wáéíóúÁÉÍÓÚñÑ\\s]+ & [\\wáéíóúÁÉÍÓÚñÑ\\s]+, \\d{4}[a-z]?)|' + \\\n",
    "                    r'(?:[\\wáéíóúÁÉÍÓÚñÑ\\s]+, (?:\\d+ de [a-zá-úñ]+ de \\d{4}|s\\.f\\.|(?:\\d{4}[a-z]?))(?:, p\\. \\d+)?(?:, \\d{4}[a-z]?)?)|' + \\\n",
    "                    r'(?:\\d{4}, como se citó en [\\wáéíóúÁÉÍÓÚñÑ\\s]+, \\d{4})|' + \\\n",
    "                    r'(?:[\\wáéíóúÁÉÍÓÚñÑ\\s]+, \\d{4}, como se citó en [\\wáéíóúÁÉÍÓÚñÑ\\s]+, \\d{4})|' + \\\n",
    "                    r'(?:p\\. \\d+)|' + \\\n",
    "                    r'(?:traducción propia, p\\. \\d+)|' + \\\n",
    "                    r'(?:s\\.f\\.)|' + \\\n",
    "                    r'(?:\\d{4})|' + \\\n",
    "                    r'(?:[\\wáéíóúÁÉÍÓÚñÑ\\s]+ \\d{4}(?:, [\\wáéíóúÁÉÍÓÚñÑ\\s]+ \\d{4})*(?:, [\\wáéíóúÁÉÍÓÚñÑ\\s]+, \\d{4})?)' + \\\n",
    "                r')' + \\\n",
    "                r'(?:; [\\wáéíóúÁÉÍÓÚñÑ\\s]+(?:, \\d{4}|& [\\wáéíóúÁÉÍÓÚñÑ\\s]+, \\d{4}))*' + \\\n",
    "                r'\\)'\n",
    "\n",
    "# Patrón específico para la cita 7 (El País, 12 de abril de 2023)\n",
    "spanish_date_cite_pattern = r'\\([^,)]+, \\d+ de [a-zá-úñ]+ de \\d{4}\\)'\n",
    "\n",
    "# Patrón específico para la cita 21 (Dundes 1981, Elworthy 2004, Maloney, 1976)\n",
    "multiple_authors_cite_pattern = r'\\((?:[\\wáéíóúÁÉÍÓÚñÑ]+ \\d{4}(?:, [\\wáéíóúÁÉÍÓÚñÑ]+ \\d{4})*)(?:, [\\wáéíóúÁÉÍÓÚñÑ]+, \\d{4})?\\)'\n",
    "\n",
    "cites_pattern = r'(?:' + cites_general_pattern + '|' + spanish_date_cite_pattern + '|' + multiple_authors_cite_pattern + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efa9dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleExtractedData:\n",
    "    def __init__(self, pdf_path: str):\n",
    "        self.pdf_path: str = pdf_path\n",
    "        self.headers: set[str] = set()\n",
    "        self.footers: set[str] = set()\n",
    "        self.footnotes_lines: list[dict[str, float]] = []\n",
    "        self.start_page: int = 0\n",
    "\n",
    "def extract_data_article(pdf_path) -> ArticleExtractedData:\n",
    "    data = ArticleExtractedData(pdf_path)\n",
    "    headers_counter: map[str, int] = {}\n",
    "    footers_counter: map[str, int] = {}\n",
    "    found_page = None\n",
    "\n",
    "    for i, page in enumerate(extract_pages(pdf_path)):\n",
    "        height = page.bbox[3]\n",
    "        cutoff = height * 0.15\n",
    "\n",
    "        footnote_line = extract_possible_footnote_line(pdf_path, page, i)\n",
    "        data.footnotes_lines.append(footnote_line)\n",
    "\n",
    "        for element in page:\n",
    "            if not isinstance(element, (LTTextBox, LTTextBox, LTTextContainer)):\n",
    "                continue\n",
    "            txt = element.get_text().strip()\n",
    "            if element.bbox[3] <= cutoff:\n",
    "                footers_counter[txt] = footers_counter.get(txt, 0) + 1\n",
    "            if element.bbox[1] >= height - cutoff:\n",
    "                headers_counter[txt] = headers_counter.get(txt, 0) + 1\n",
    "            \n",
    "            # Stop searching for abstract after 3 pages\n",
    "            if found_page is not None or i > 2:\n",
    "                continue\n",
    "\n",
    "            text_semiclean = re.sub(duplicated_spaces, \" \", txt).strip()\n",
    "            if re.search(abstract, text_semiclean, re.IGNORECASE):\n",
    "                found_page = i\n",
    "\n",
    "\n",
    "    data.headers = {k for k, v in headers_counter.items() if v > 1 and len(k) > 0}\n",
    "    data.footers = {k for k, v in footers_counter.items() if v > 1 and len(k) > 0}\n",
    "    if found_page is not None:\n",
    "        data.start_page = found_page\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(text: str) -> str:\n",
    "    return text.replace(\"á\", \"a\").replace(\"é\", \"e\").replace(\"í\", \"i\").replace(\"ó\", \"o\").replace(\"ú\", \"u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f922226a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'espacios público s y lasa u t ó n o m a s'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separate_words(\"espaciospúblicosylasautónomas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1254ce",
   "metadata": {},
   "source": [
    "**los footnote references se llevan los años, en textos como: en 1592. Aquello [...]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a837c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stop_conditions(text) -> bool:\n",
    "\treturn any([\n",
    "\t\tre.search(references_re, text, flags=re.MULTILINE),\n",
    "\t])\n",
    "\n",
    "def clean_unwanted_patterns(text) -> str:\n",
    "\t# Eliminar patrones como \"Recibido el 12 de marzo de 2021.\"\n",
    "\ttext = re.sub(version_logs, \"\", text).strip()\n",
    "\n",
    "\t# text = re.sub(cites_pattern, \"\", text).strip()\n",
    "\t# text = re.sub(footnote_patterns, \"\", text, flags=re.MULTILINE).strip()\n",
    "\n",
    "\t# Eliminar las referencias de las notas al pie y reemplazarlas por un punto\n",
    "\t# text = re.sub(footnote_references, \".\", text).strip()\n",
    "\n",
    "\treturn text\n",
    "\n",
    "def avoid_unwanted_texts(text) -> str:\n",
    "\treturn text\n",
    "\n",
    "def clean_page(text) -> str:\n",
    "\ttext = text.replace(\"-\\n\", \"\")\n",
    "\ttext = re.sub(duplicated_spaces, \" \", text).strip()\n",
    "\ttext = text.replace(\"«\", \"\").replace(\"»\", \"\")\n",
    "    # text = remove_accents(text)\n",
    "\treturn text\n",
    "\n",
    "# def corrections(text: str) -> str:\n",
    "#     words = text.split()\n",
    "#     corrected = []\n",
    "#     for word in words:\n",
    "#         if len(word) < 3:\n",
    "#             continue\n",
    "#         corrected.append(separate_words(word))\n",
    "#     return \" \".join(corrected)\n",
    "\n",
    "def extract_page_text(page: LTPage, page_number: int, data: ArticleExtractedData) -> str:\n",
    "    text = \"\"\n",
    "\n",
    "    for element in page:\n",
    "        if not isinstance(element, (LTTextBoxHorizontal, LTTextBox, LTTextContainer)):\n",
    "            continue\n",
    "\n",
    "        _, __, ___, y2 = element.bbox\n",
    "        footnote_line = data.footnotes_lines[page_number]\n",
    "        if y2 <= (footnote_line[\"y1\"] if footnote_line is not None else -1):\n",
    "            break\n",
    "\n",
    "        txt = element.get_text().strip()\n",
    "        if txt.isdigit() or txt in data.headers or txt in data.footers:\n",
    "            continue\n",
    "\n",
    "        txt = avoid_unwanted_texts(txt)\n",
    "        if check_stop_conditions(txt):\n",
    "            break\n",
    "\n",
    "        text += txt\n",
    "\n",
    "    text = clean_unwanted_patterns(text)\n",
    "    text = clean_page(text)\n",
    "    # text = corrections(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81362f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constantemente con los otros miembros de la élite de poder en materias referentes a aumento de impuestos, envío de remesas y colaboración comercial. Mantener el equilibrio no fue tarea fácil y, de hecho, hubo coyunturas muy tensas entre los diversos actores sociales, sobre todo cuando se intentó forzar a los reinos americanos a realizar mayores aportes pecuniarios a la península. Los beneméritos nunca cejaron en sus intentos de obtener los puestos que los propios virreyes repartían entre sus criados. La Iglesia, por su parte, se mantuvo firme en defender los privilegios concedidos desde el siglo XVI, que la favorecían con la percepción de diezmos, inmunidad, cesión de tierras y beneficios fiscales. La administración fue ineficiente y progresivamente ciertas funciones del Estado fueron delegándose en manos privadas, particularmente en el Consulado.4 Finalmente, los comerciantes de Lima formaron grandes consorcios en el interior del virreinato que les permitieron lanzar una ofensiva contundente en el comercio atlántico a través de sus factores —los peruleros—, que dejó en malas condiciones tanto al comercio peninsular como al mismo sistema de galeones.5En este contexto, y como expresión de la práctica política de la época, aparecieron diversos escritos sobre el Perú que trataron de diagnosticar y remediar alguno de estos males aunque, como afirma Amadori, la historiografía americanista no les ha prestado mucha atención.6. El fenómeno que más ha sido estudiado es la aparición de arbitrios en las décadas de 1620 y 1630, incentivada por el conde-duque de Olivares, la mayoría de los cuales tenía como finalidad hacer más eficiente la extorsión fiscal de las Indias.7 Un buen ejemplo es el Parecer del contador Hernando de Valencia, cuyo arbitrio explicaba los daños que había ocasionado la plantación de viñas en el Perú y recomendaba volver a prohibir el comercio de vinos peruanos para aumentar el consumo de aquellos procedentes de España.8 El arbitrio de Diego Pérez Gallego estaba orientado, por el contrario, a exaltar las virtudes del gobierno del virrey conde de Chinchón, pero también incluía un diagnóstico de los principales problemas del Perú y los remedios necesarios para subsanar los errores.9\n"
     ]
    }
   ],
   "source": [
    "art = articles[1]\n",
    "data = extract_data_article(art)\n",
    "page = extract_page(art, 3)\n",
    "print(extract_page_text(page, 2, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "183559bb16e20cbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:02:41.521599Z",
     "start_time": "2025-02-25T22:02:41.345192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498.898 697.323\n",
      "498.898 697.323\n",
      "498.898 697.323\n",
      "<LTTextBoxHorizontal(0) 131.553,617.258,367.336,625.258 'REFORMA, ORDEN Y CONCIERTO EN EL PERÚ DEL SIGLO XVII\\n'>\n",
      "<LTTextBoxHorizontal(1) 85.038,387.647,413.873,601.046 'constantemente  con  los  otros  miembros  de  la  élite  de  poder  en  materias\\nreferentes  a  aumento  de  impuestos,  envío  de  remesas  y  colaboración\\ncomercial.  Mantener  el  equilibrio  no  fue  tarea  fácil  y,  de  hecho,  hubo\\ncoyunturas muy tensas entre los diversos actores sociales, sobre todo cuan-\\ndo  se  intentó  forzar  a  los  reinos  americanos  a  realizar  mayores  aportes\\npecuniarios a la península. Los «beneméritos» nunca cejaron en sus inten-\\ntos de obtener los puestos que los propios virreyes repartían entre sus cria-\\ndos. La Iglesia, por su parte, se mantuvo firme en defender los privilegios\\nconcedidos desde el siglo XVI, que la favorecían con la percepción de diez-\\nmos, inmunidad, cesión de tierras y beneficios fiscales. La administración\\nfue ineficiente y progresivamente ciertas funciones del Estado fueron dele-\\ngándose en manos privadas, particularmente en el Consulado.4 Finalmente,\\nlos comerciantes de Lima formaron grandes consorcios en el interior del\\nvirreinato que les permitieron lanzar una ofensiva contundente en el comer-\\ncio  atlántico  a  través  de  sus  factores  —los  «peruleros»—,  que  dejó  en\\nmalas condiciones tanto al comercio peninsular como al mismo sistema de\\ngaleones.5\\n'>\n",
      "<LTTextBoxHorizontal(2) 85.034,197.898,413.865,385.998 'En este contexto, y como expresión de la práctica política de la épo-\\nca, aparecieron diversos escritos sobre el Perú que trataron de diagnosticar\\ny remediar alguno de estos males aunque, como afirma Amadori, la histo-\\nriografía  americanista  no  les  ha  prestado  mucha  atención.6.  El  fenómeno\\nque  más  ha  sido  estudiado  es  la  aparición  de  arbitrios  en  las  décadas  de\\n1620 y 1630, incentivada por el conde-duque de Olivares, la mayoría de los\\ncuales  tenía  como  finalidad  hacer  más  eficiente  la  extorsión  fiscal  de  las\\nIndias.7 Un  buen  ejemplo  es  el  «Parecer»  del  contador  Hernando  de\\nValencia, cuyo arbitrio explicaba los daños que había ocasionado la planta-\\nción de viñas en el Perú y recomendaba volver a prohibir el comercio de\\nvinos  peruanos  para  aumentar  el  consumo  de  aquellos  procedentes  de\\nEspaña.8 El arbitrio de Diego Pérez Gallego estaba orientado, por el contra-\\nrio, a exaltar las virtudes del gobierno del virrey conde de Chinchón, pero\\ntambién incluía un diagnóstico de los principales problemas del Perú y los\\nremedios necesarios para subsanar los errores.9\\n'>\n",
      "<LTTextBoxHorizontal(3) 112.220,138.453,413.854,183.253 '4 Suárez, 2012.\\n5 Suárez, 2009.\\n6 Amadori, 2009, 152.\\n7 Idem; Amadori, 2013, 139; Bronner, 1974, 1975, 1981, 1981a.\\n8 Archivo General de Indias (AGI), Lima, 162, Parecer del contador Hernando de Valencia,\\n'>\n",
      "<LTTextBoxHorizontal(4) 85.036,129.253,116.788,137.253 'año 1633.\\n'>\n",
      "<LTTextBoxHorizontal(5) 112.220,120.053,220.109,128.053 '9 Pérez Gallego, 1945, 295-326.\\n'>\n",
      "<LTTextBoxHorizontal(6) 85.039,93.542,327.778,99.542 'Anu. estud. am., 71, 1, enero-junio, 2014, 25-46. ISSN: 0210-5810. DOI: 10.3989/aeamer.2014.1.02\\n'>\n",
      "<LTTextBoxHorizontal(7) 402.858,93.541,413.858,104.541 '27\\n'>\n",
      "<LTRect 85.039,93.543,413.858,626.457>\n",
      "<LTRect 85.039,93.543,413.858,192.756>\n",
      "<LTLine 85.039,189.895,136.063,189.895>\n",
      "<LTRect 85.039,600.945,413.858,626.457>\n",
      "<LTRect 85.039,93.543,413.858,119.055>\n",
      "<LTRect 385.512,93.543,413.858,119.055>\n"
     ]
    }
   ],
   "source": [
    "page = extract_page(articles[1], 3)\n",
    "for element in page:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a49e9cf3823b093d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:02:59.680542Z",
     "start_time": "2025-02-25T22:02:56.510018Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def detect_lines_in_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            lines = page.lines  # Extrae todas las líneas de la página\n",
    "\n",
    "            # Filtrar líneas horizontales (y0 ≈ y1 indica una línea horizontal)\n",
    "            horizontal_lines = [line for line in lines if abs(line[\"y0\"] - line[\"y1\"]) < 1]\n",
    "\n",
    "            if horizontal_lines:\n",
    "                print(f\"Página {i+1}: {len(horizontal_lines)} ({(page.width, page.height)}) línea(s) horizontal(es) detectada(s).\")\n",
    "                for line in horizontal_lines:\n",
    "                    print(f\"  - Coordenadas: {line}\")\n",
    "\n",
    "detect_lines_in_pdf(articles[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "841c1d753b80ce10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T21:59:52.882757Z",
     "start_time": "2025-02-25T21:59:48.140777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[191.7, 317.16, 420.3, 317.16]\n",
      "[191.7, 91.08, 420.3, 91.08]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n",
      "[92.7, 744.18, 519.36, 744.18]\n"
     ]
    }
   ],
   "source": [
    "import pdfquery\n",
    "pdf = pdfquery.PDFQuery(articles[0])\n",
    "pdf.load()\n",
    "lines = pdf.pq('LTLine')\n",
    "print(len(lines))\n",
    "for line in lines:\n",
    "    print(line.get('bbox'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [os.path.join(\"data\", art) for art in os.listdir(\"data\")]\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pages(articles):\n",
    "  return [extract_pages(article) for article in articles]\n",
    "\n",
    "def bound_delete(articles):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def limpiar_fechas(texto):\n",
    "    # Regex mejorada para eliminar fechas en líneas individuales y en la misma línea\n",
    "    regex = r\"\"\n",
    "    # Reemplazar coincidencias con una cadena vacía\n",
    "    return re.sub(regex, \"\", texto).strip()\n",
    "\n",
    "# Ejemplo de texto\n",
    "texto = \"\"\"\n",
    "Recibido el 16 de enero de 2014\n",
    "Aceptado el 6 de abril de 2014\n",
    "\n",
    "Recibido: 25/09/2023. Aceptado: 06/12/2023. Publicado: 22/10/2024.\n",
    "\n",
    "Recibido, 27 de noviembre de 2019\n",
    "Segunda versión, 4 de marzo de 2020\n",
    "Aceptado, 23 de marzo de 2020\n",
    "\"\"\"\n",
    "\n",
    "# Limpiar el texto\n",
    "texto_limpio = limpiar_fechas(texto)\n",
    "\n",
    "print(texto_limpio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
